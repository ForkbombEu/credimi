#+TITLE: Unify Scheduled/CLI Pipeline Starts with Semaphore Queue
#+SUBTITLE: Eliminate “start immediately + wait inside pipeline” by enqueueing all mobile-runner pipeline starts (Run now / CLI / Schedules) into the same FIFO
#+DATE: 2026-02-06
#+KEYWORDS: temporal, schedules, pipeline, semaphore, queue, cli, pocketbase, mobile-automation

* DONE [#A] Add a scheduled “enqueue-only” workflow (no pipeline execution)
- Effort :: M
- Goal :: Ensure Temporal schedules never start the pipeline workflow directly; they enqueue a run ticket and return immediately (no waiting time counted in pipeline workflow runtime).
- Notes ::
  - New workflow type runs on `pipeline.PipelineTaskQueue` (same worker as “Dynamic Pipeline Workflow”).
  - Input explicitly carries “who/where” metadata needed for queued runs (namespace, app_url, user info, optional global runner override, max queue limit).

** DONE [#A] Define workflow contract and determinism-safe IDs
- Why :: A schedule tick must be fast, deterministic, and safe under retries; ticket identity must be stable and unique without `uuid.NewString()` in workflow code.
- Change ::
  - Add workflow `workflows.ScheduledPipelineEnqueueWorkflow` (new file e.g. `pkg/workflowengine/workflows/scheduled_pipeline_enqueue.go`) with:
    - `Name()` constant (e.g. `Scheduled Pipeline Enqueue Workflow`).
    - Input DTO `ScheduledPipelineEnqueueWorkflowInput`:
      - `PipelineIdentifier string` (canonify identifier, same as API `pipeline_identifier`)
      - `OwnerNamespace string` (organization canonified name; used as semaphore owner namespace and pipeline Temporal namespace)
      - `PipelineConfig map[string]any` (must include at least `app_url`; may include `user_name`, `user_mail`, `app_name`, `app_logo`, `global_runner_id`)
      - `GlobalRunnerID string` (optional override when YAML omits `runtime.global_runner_id`)
      - `MaxPipelinesInQueue int` (snapshot at schedule-create time; keeps parity with `/api/pipeline/queue` without adding new internal endpoints)
  - Ticket ID strategy (deterministic + unique per tick):
    - `ticket_id := "sched/" + workflowID + "/" + runID` (from `workflow.GetInfo(ctx)`).
    - `enqueued_at := workflow.Now(ctx).UTC()`.
  - YAML fetch at runtime:
    - Use existing `HTTPActivity` to call `POST /api/canonify/identifier/validate` (same response parsing as the old `PipelineWorkflow.handleScheduledRun`), and extract `record.yaml`.
  - Runner resolution (same semantics as queue endpoint, plus schedule override):
    - Parse runner info via `runners.ParsePipelineRunnerInfo(yaml)`.
    - If global runner is needed, prefer:
      1) `runtime.global_runner_id` from YAML, else
      2) `input.GlobalRunnerID`, else
      3) error (missing global runner).
    - Compute runner IDs with `runners.RunnerIDsWithGlobal(...)`, then `sort.Strings`.
  - Enqueue:
    - Call a new activity (see next L1) that encapsulates “ensure semaphore workflow + enqueue update + aggregate response”.
  - If runnerIDs resolves to empty:
    - Treat as configuration error and fail the scheduled tick with a clear application error (scheduled pipelines are assumed to be mobile-runner pipelines; non-runner schedules are out of scope for this change).
- Tests ::
  - Add a Temporal workflow unit test (workflow test suite) that:
    - stubs the HTTP activity response with YAML,
    - asserts the enqueue activity is invoked with the expected `TicketID`, `OwnerNamespace`, runner IDs, YAML, and config,
    - verifies determinism-safe IDs (no random UUID usage).
- Done when :: A schedule tick results in a run ticket added to the runner semaphore queue and the scheduled workflow completes quickly (seconds), without starting the pipeline workflow directly.

* DONE [#A] Introduce a reusable “enqueue run ticket” activity (ports/adapters)
- Effort :: M
- Goal :: Reuse the exact same enqueue semantics across HTTP handlers and the new scheduled workflow, without duplicating Temporal client/update logic inside workflow code.
- Notes ::
  - This is the only place that touches Temporal client APIs for enqueueing from a workflow context.
  - Keep it minimal: mirror `pkg/internal/apis/handlers/pipeline_queue_handler.go` behavior and reuse existing request/response structs where sensible.

** DONE [#A] Implement enqueue activity + shared aggregation
- Why :: Workflows cannot instantiate Temporal clients; enqueue must be done in an activity while preserving the same queue semantics (leader runner, multi-runner coordination, limit enforcement).
- Change ::
  - Add `activities.EnqueuePipelineRunTicketActivity` (new file e.g. `pkg/workflowengine/activities/enqueue_pipeline_run_ticket.go`) that:
    - Ensures each `runnerID` has a semaphore workflow running (same logic as `ensureRunQueueSemaphoreWorkflowTemporal`).
    - Sends `workflows.MobileRunnerSemaphoreEnqueueRunRequest` to each runner via `UpdateWorkflow` (same as `enqueueRunTicketTemporal`).
    - Aggregates per-runner responses into a single output mirroring `PipelineQueueStatusResponse` fields needed by callers.
  - Inputs/outputs:
    - Input should carry: `TicketID`, `OwnerNamespace`, `EnqueuedAt`, `RunnerIDs`, `PipelineIdentifier`, `YAML`, `PipelineConfig`, `Memo`, `MaxPipelinesInQueue`.
    - Output should include: `Status`, `Position`, `LineLen`, plus the per-runner statuses (for parity/debug).
  - Register the new activity in the pipeline worker (`pkg/workflowengine/hooks/hook.go`) or via `registry.PipelineInternalRegistry`.
  - Optional (recommended): factor `aggregateRunQueueStatus` into a small shared helper (currently in handler) so API + workflow use the same aggregation rules.
- Tests ::
  - Unit test the activity with a stub temporal client factory (pattern used by `StartQueuedPipelineActivity`) to verify:
    - correct workflow IDs and update names are used,
    - queue-limit application errors are surfaced with stable error typing.
- Done when :: The scheduled workflow can enqueue via this activity and the HTTP queue handler can optionally reuse the same aggregation helper without behavioral drift.

* DONE [#A] Switch schedule creation to the new scheduled-enqueue workflow
- Effort :: M
- Goal :: Ensure schedules created from the API never reference the pipeline workflow directly, and preserve global runner visibility in the UI.
- Notes ::
  - Primary entrypoint is `pkg/internal/apis/handlers/schedules_handlers.go` (`startScheduledPipelineWithOptions`).
  - Schedule list/enrichment uses `pkg/internal/pb/schedules.go` to infer runners (including global runner) from schedule action args.
  - Rollout assumption: existing schedules are deleted and recreated manually (no automated migration in scope).

** DONE [#A] Update schedule handler wiring and enrichment decoding
- Why :: Without updating both schedule creation and enrichment decoding, schedules will either keep starting the wrong workflow or lose runner visibility (esp. global runner).
- Change ::
  - In `pkg/internal/apis/handlers/schedules_handlers.go`:
    - Set `Action.Workflow` to `workflows.ScheduledPipelineEnqueueWorkflowName` (new workflow name).
    - Set `Action.Args` to the new input DTO (carry `PipelineIdentifier`, `OwnerNamespace`, config, `GlobalRunnerID`, and `MaxPipelinesInQueue`).
    - Keep existing schedule memo fields (`test`, `pipelineID`) unchanged for UI display.
    - Snapshot `organizations.max_pipelines_in_queue` at schedule-create time and pass it in the workflow input.
  - In `pkg/internal/pb/schedules.go`:
    - Extend `readGlobalRunnerIDFromScheduleDescription()` to also decode the new scheduled-enqueue workflow input type and return `GlobalRunnerID` (or fallback to config `global_runner_id`).
- Tests ::
  - Add/extend unit tests to assert:
    - schedule creation uses the new workflow name (mock Temporal client/schedule client or inject a factory),
    - enrichment correctly shows runners when `GlobalRunnerID` is present in the new args.
- Done when :: New schedules enqueue runs instead of starting pipelines, and the schedules UI continues to show correct runner lists.

* DONE [#A] Remove the “scheduled run” mode from the pipeline workflow input
- Effort :: M
- Goal :: Eliminate `PipelineWorkflowInput.Scheduled` and the in-workflow DB fetch path; scheduled behavior belongs to the new scheduled-enqueue workflow.
- Notes ::
  - This is an intentional behavior shift: pipeline workflows should always start with full YAML/definition already present (either from API start or from the semaphore’s `StartQueuedPipelineActivity`).

** DONE [#A] Delete `Scheduled` flag + `handleScheduledRun` implementation
- Why :: The scheduled-enqueue workflow now owns “fetch YAML at runtime” and “queue insertion”; keeping the old mode invites regressions and still risks long workflow runtimes.
- Change ::
  - In `pkg/workflowengine/pipeline/pipeline.go`:
    - Remove `Scheduled bool` from `PipelineWorkflowInput`.
    - Remove the `if input.Scheduled { ... }` branch and delete `handleScheduledRun`.
    - Ensure any remaining callers no longer set `Scheduled`.
  - Update schedule-creation code paths that previously relied on `Scheduled=true` (covered above).
- Tests ::
  - Update existing pipeline tests to stop constructing `PipelineWorkflowInput{Scheduled:true,...}`.
  - Add a unit test ensuring the pipeline workflow errors clearly if `WorkflowDefinition` is missing (guardrail for any accidental scheduled-style start).
- Done when :: No code path starts a pipeline workflow with only `pipeline_id` payload; scheduled runs are always enqueued and later started via `StartQueuedPipelineActivity`.

* DONE [#A] Eliminate “acquire permit and wait inside pipeline workflow” logic
- Effort :: L
- Goal :: Ensure mobile-automation pipelines never block on permit acquisition inside the pipeline workflow; they must be semaphore-managed (queued) or fail fast.


** DONE [#A] Make non-semaphore mobile runs fail fast (no waiting)
- Why :: This is the root cause of inflated workflow runtime and schedule overlap issues; waiting must move out of the pipeline workflow entirely.
- Change ::
  - In `pkg/workflowengine/pipeline/mobile_automation_hooks.go`:
    - Remove `acquireRunnerPermits` call path.
    - If mobile runner IDs are present and `isSemaphoreManagedRun(config)` is false:
      - return a stable application error (e.g., `MissingOrInvalidConfig`) stating “mobile-runner pipelines must be started via queue/semaphore”.
  - In `pkg/internal/apis/handlers/pipeline_handler.go` (`POST /api/pipeline/start`):
    - Parse runner IDs from YAML (reuse `runners.ParsePipelineRunnerInfo`).
    - If runner IDs are present, do **not** start a workflow; return `409 Conflict` with a clear error pointing to `POST /api/pipeline/queue`.
    - Non-mobile pipelines remain unchanged.
  - Keep permit-release logic in cleanup for legacy runs (only if permits are present in runData).
- Tests ::
  - Update `pkg/workflowengine/pipeline/mobile_automation_hooks_test.go`:
    - Replace “acquire permits” tests with a failure-fast assertion when missing semaphore metadata.
  - Add handler unit test ensuring `/api/pipeline/start` returns 409 for runner pipelines and does not call Temporal execute.
- Done when :: No mobile-runner pipeline start path can result in “waiting for permit” inside the pipeline workflow; such starts either enqueue (queue endpoints) or fail immediately with a clear message.

* DONE [#B] Update CLI start flow to enqueue and print queue position
- Effort :: S
- Goal :: Make `credimi pipeline` behave like “Run now”: enqueue runner pipelines and show the queue position; fallback to direct start only for non-runner pipelines.
- Notes ::
  - CLI cannot import `pkg/internal/...` packages; it must infer behavior from API responses (or add a dedicated API endpoint).

** DONE [#B] Implement enqueue-first CLI logic + output contract
- Why :: Users starting from CLI need immediate feedback that the run is queued and where it sits; also avoid starting workflows that will be rejected by the new fail-fast guardrails.
- Change ::
  - In `cmd/cli/pipeline.go`:
    - Attempt `POST /api/pipeline/queue` first with `{pipeline_identifier, yaml}`.
    - If 200: print JSON including:
      - `ticket_id`, `runner_ids`, and queue `position`/`line_len`,
      - `position_human := position + 1` (explicitly label it as 1-based).
    - If 400 with “no runner ids resolved…”: fallback to `POST /api/pipeline/start` (non-runner pipeline).
    - If 409 from `/api/pipeline/start`: print a helpful message and ensure the user sees they must use queue (should be unreachable if enqueue-first is implemented).
- Tests ::
  - Update/add `cmd/cli/pipeline_test.go` with an `httptest.Server` that simulates:
    - queued response (assert output includes `position_human`),
    - non-runner response (assert fallback to `/start`).
- Done when :: CLI prints queue position for queued runs and remains functional for non-runner pipelines without requiring the user to know which endpoint to call.

* DONE [#A] Refactor scheduled-enqueue workflow to satisfy `workflowengine.Workflow`
- Effort :: S
- Goal :: Keep workflow registration consistent (everything implements `workflowengine.Workflow`) and eliminate the startup panic.
- Notes ::
  - Current panic: `panic: interface conversion: *workflows.ScheduledPipelineEnqueueWorkflow is not workflowengine.Workflow: missing method ExecuteWorkflow`.
  - Root cause: `pkg/workflowengine/hooks/hook.go` registers `registry.PipelineInternalRegistry` workflows via `step.NewFunc().(workflowengine.Workflow)`, but `pkg/workflowengine/workflows/scheduled_pipeline_enqueue.go` currently uses a typed workflow signature (`Workflow(ctx, ScheduledPipelineEnqueueWorkflowInput)`), so it cannot satisfy the interface.
  - Assumption: there are no existing schedules yet, so changing the schedule action arg shape is acceptable (no migration/compat needed).

** DONE [#A] Implement `Workflow` + `ExecuteWorkflow` using `workflowengine.BuildWorkflow`
- Why :: Aligns with the existing workflow pattern and makes the internal registry + pipeline worker registration path safe.
- Change ::
  - In `pkg/workflowengine/workflows/scheduled_pipeline_enqueue.go`:
    - Change the public workflow entrypoint to `Workflow(ctx workflow.Context, input workflowengine.WorkflowInput) (workflowengine.WorkflowResult, error)`.
    - Add `ExecuteWorkflow(ctx workflow.Context, input workflowengine.WorkflowInput) (workflowengine.WorkflowResult, error)` and move the current enqueue logic there.
    - Update `NewScheduledPipelineEnqueueWorkflow()` to set `w.WorkflowFunc = workflowengine.BuildWorkflow(w)` (same pattern as `EWCWorkflow`, `WalletWorkflow`, etc.).
    - Decode payload via `workflowengine.DecodePayload[ScheduledPipelineEnqueueWorkflowInput](input.Payload)`.
    - Treat `input.Config` as the pipeline config (must include `app_url`), and keep augmenting it with `namespace` and `global_runner_id` as needed before enqueue.
    - Add a compile-time assertion to prevent regressions: `var _ workflowengine.Workflow = (*ScheduledPipelineEnqueueWorkflow)(nil)`.
  - In `pkg/workflowengine/registry/registry.go`:
    - Keep `scheduled-pipeline-enqueue` in `PipelineInternalRegistry` (now it will satisfy `workflowengine.Workflow` and register safely).
- Tests ::
  - Covered by the updated scheduled-enqueue workflow unit test and schedule handler tests in the next step.
- Done when :: `ScheduledPipelineEnqueueWorkflow` satisfies `workflowengine.Workflow` at compile time and can be instantiated via `step.NewFunc().(workflowengine.Workflow)` without panicking.

** DONE [#A] Update schedule creation to pass `workflowengine.WorkflowInput`
- Why :: After the refactor, the workflow expects the standard wrapper input; schedules should pass payload+config consistently with other workflow starts.
- Change ::
  - In `pkg/internal/apis/handlers/schedules_handlers.go` (`startScheduledPipelineWithOptions`):
    - Change the schedule action `Args` from a raw `workflows.ScheduledPipelineEnqueueWorkflowInput{...}` to:
      - `workflowengine.WorkflowInput{Payload: workflows.ScheduledPipelineEnqueueWorkflowInput{...}, Config: config}`
    - Ensure `config` includes `app_url` (since `workflowengine.BuildWorkflow` builds `TemporalUI` from `input.Config["app_url"]`).
  - In `pkg/internal/pb/schedules.go`:
    - Update any payload conversion logic that currently expects `ScheduledPipelineEnqueueWorkflowInput` at the top-level to handle the new `workflowengine.WorkflowInput` wrapper (while still decoding the embedded `ScheduledPipelineEnqueueWorkflowInput` payload).

- Tests ::
  - Update `pkg/workflowengine/workflows/scheduled_pipeline_enqueue_test.go` to execute the workflow via the standard entrypoint and wrapper input:
    - `env.ExecuteWorkflow(w.Workflow, workflowengine.WorkflowInput{Payload: ScheduledPipelineEnqueueWorkflowInput{...}, Config: map[string]any{\"app_url\": ...}})`
    - Assert the enqueue activity receives the expected values as before.
  - Update `pkg/internal/apis/handlers/schedules_handlers_test.go` to assert schedule action args now contain `workflowengine.WorkflowInput` with:
    - `Payload` decodable as `workflows.ScheduledPipelineEnqueueWorkflowInput`,
    - `Config` equal (or superset) of the config passed by the handler.
  - Add a small registry guardrail test (optional but cheap): iterate `registry.PipelineInternalRegistry` and assert every `TaskWorkflow` `NewFunc()` implements `workflowengine.Workflow`.
- Done when :: Pipeline worker starts without panic, and creating/executing a schedule enqueues a run ticket successfully using the `workflowengine.WorkflowInput` wrapper.

* DONE [#B] Prefix scheduled queued pipeline WorkflowID with `Sched-`
- Effort :: S
- Goal :: Make pipeline workflows started by the semaphore queue clearly distinguishable when their enqueue request originated from a Temporal schedule.
- Notes ::
  - Keep the existing `Pipeline-` prefix for compatibility; insert `Sched-` immediately after it (e.g. `Pipeline-Sched-...`).
  - Detect “scheduled enqueue” via `ticket_id` prefix `sched/` (set by `ScheduledPipelineEnqueueWorkflow`), so no API surface changes are needed.

** DONE [#B] Add `Pipeline-Sched-` prefix in `StartQueuedPipelineActivity`
- Why :: Today, queued pipeline runs started from schedules look identical to ad-hoc queued runs; this makes triage and metrics slicing harder.
- Change ::
  - In `pkg/workflowengine/activities/queued_pipeline.go` (`StartQueuedPipelineActivity.Execute`), when generating `options.Options.ID`:
    - If `payload.TicketID` starts with `sched/`, use `Pipeline-Sched-<canon pipeline name>-<uuid>`.
    - Otherwise keep the existing `Pipeline-<canon pipeline name>-<uuid>`.
  - Keep the logic local to the queued-start path (do not change `PipelineWorkflow.Start`), since the request is specifically about pipeline workflows started from the semaphore.
- Tests ::
  - Extend `pkg/workflowengine/activities/queued_pipeline_test.go` with a small unit test that:
    - Uses a fake Temporal client that captures `client.StartWorkflowOptions.ID`,
    - Executes the activity with `TicketID: "sched/wf/run"` and asserts the captured ID starts with `Pipeline-Sched-`,
    - Executes the activity with a non-scheduled ticket (e.g. `"ticket-1"`) and asserts the captured ID starts with `Pipeline-` and does not include `Pipeline-Sched-`.
- Done when :: A scheduled tick enqueues a run ticket and the resulting pipeline workflow ID returned by the semaphore status includes `Pipeline-Sched-...`.

* DONE [#A] Show queued (not-started) pipeline runs in listings + cancel from queue
- Effort :: M
- Goal :: Both `/api/pipeline/list-workflows` and `/api/compliance/checks` include the authenticated user’s queued (not-yet-started) pipeline run tickets, including queue position + queue length, and the UI shows them as “Queued” with a working cancel action that removes them from the semaphore queue.
- Notes ::
  - Scope: only “queued” tickets (status `queued` in the mobile-runner semaphore), excluding `starting` and beyond, to satisfy “queued and not already started”.
  - Runner ownership is irrelevant: queued runs may target runners owned by other organizations; discovery must still find them and report queue position/length from those semaphores.
  - Runner display: when `runner_id` values are canonified paths (including other orgs), APIs can resolve `runner_records` for display; when `runner_id` is a raw record ID, resolution may be best-effort (still return `runner_ids` so UI can function).
  - Queue metrics:
    - `position` stays 0-based to match existing `/api/pipeline/queue/{ticket}` responses (UI can keep `+1` display).
    - `line_len` is the full queue length for the runner semaphore (not filtered by owner namespace).
    - For multi-runner pipelines, API returns the aggregate “effective” position/line_len using the existing rule: `max(position)` and `max(line_len)` across required runners (same as `pkg/internal/runqueue.AggregateRunnerStatuses`).
  - Compatibility: avoid breaking existing response shapes; add only optional fields (e.g. `queue`) and keep existing fields untouched.
  - Security: API must only ever return queued tickets for the caller’s organization canonified namespace (do not accept a client-provided namespace).

** DONE [#A] Add a semaphore query to list queued tickets for an owner namespace
- Why :: Queued runs are not Temporal workflow executions yet, so list endpoints cannot discover them via `ListWorkflowExecutions`; we need a deterministic, read-only view of the semaphore run queue.
- Change ::
  - In `pkg/workflowengine/mobilerunnersemaphore/types.go`:
    - Add a new query name constant (e.g. `ListQueuedRunsQuery = "ListQueuedRuns"`).
    - Add a compact view DTO that intentionally excludes YAML/config payloads (e.g. `MobileRunnerSemaphoreQueuedRunView` with `ticket_id`, `owner_namespace`, `pipeline_identifier`, `enqueued_at`, `leader_runner_id`, `required_runner_ids`, `status`, `position`, `line_len`).
  - In `pkg/workflowengine/workflows/mobile_runner_semaphore_aliases.go`:
    - Export the new query constant via `workflows.MobileRunnerSemaphoreListQueuedRunsQuery`.
    - Re-export the new view type as an alias for handler-side decoding.
  - In `pkg/workflowengine/workflows/mobile_runner_semaphore.go`:
    - Register a query handler for `ListQueuedRunsQuery` with signature `(ownerNamespace string) ([]MobileRunnerSemaphoreQueuedRunView, error)`.
    - Implementation strategy (deterministic, stable ordering):
      - Iterate `r.runQueue` in order.
      - For each `ticketID`, lookup `r.runTickets[ticketID]`, filter `state.Status == queued` and `state.Request.OwnerNamespace == ownerNamespace`.
      - Compute `position, lineLen := r.runQueuePosition(ticketID)` and populate the view.
- Tests ::
  - In `pkg/workflowengine/workflows/mobile_runner_semaphore_test.go`:
    - Enqueue multiple tickets across at least 2 owner namespaces, then query `ListQueuedRunsQuery` for one owner and assert:
      - Only that owner’s tickets are returned,
      - Order matches `runQueue` order,
      - `position` and `line_len` reflect the underlying queue correctly.
- Done when :: The semaphore workflow can answer “list queued tickets for owner namespace X” without exposing YAML/config and with correct position/queue length.

** DONE [#A] Add an API-side queued-run aggregator (ports/adapters boundary)
- Why :: Listing endpoints need a single “my queued runs” view across potentially many runner semaphore workflows; multi-runner tickets must be deduplicated and aggregated.
- Change ::
  - Add a small helper in a new file `pkg/internal/apis/handlers/queued_pipeline_runs.go`:
    - Inputs: `ctx context.Context`, `orgNamespace string`.
    - Semaphore discovery (runner owner is irrelevant):
      - Use `temporalclient.GetTemporalClientWithNamespace(workflowengine.MobileRunnerSemaphoreDefaultNamespace)`.
      - List semaphore workflows via Temporal `ListWorkflowExecutions` with a query that selects:
        - workflow type/name `mobile-runner-semaphore` (and optionally only “open” executions), so we discover *all* runner semaphores, including runners owned by other organizations.
      - Pagination:
        - Iterate pages up to a conservative cap (configurable constant) to prevent worst-case latency.
        - Extract `runnerID` from each execution’s `workflowId` by trimming the `mobile-runner-semaphore/` prefix (do not split on `/`, runner IDs may contain `/`).
    - Temporal IO:
      - For each discovered semaphore workflow (runnerID), query `workflows.MobileRunnerSemaphoreListQueuedRunsQuery` with `orgNamespace`.
      - Apply short per-runner timeouts and tolerate missing semaphores (treat as “no queued runs” for that runner) to keep list endpoints responsive.
    - Aggregation:
      - Merge results into a `map[ticketID]QueuedRunAggregate`:
        - `position = max(position)`, `line_len = max(line_len)`,
        - Keep `pipeline_identifier`, `enqueued_at`, `required_runner_ids`, `leader_runner_id`,
        - Collect `runner_ids` from `required_runner_ids` (source of truth for cancellation).
      - Filter strictly to `status == queued`.
  - Keep the helper in handlers for now (adapter-style), but implement it as pure functions + injected Temporal query function variables (like `pipeline_queue_handler.go`) so unit tests can stub IO.
- Tests ::
  - Add unit tests in `pkg/internal/apis/handlers/pipeline_handler_test.go` (or a new `queued_pipeline_runs_test.go`) that:
    - Stubs the Temporal query helper to return overlapping tickets from two runners,
    - Asserts dedupe + max aggregation for `position` and `line_len`,
    - Asserts only `ownerNamespace == orgNamespace` is used (no client input).
- Done when :: Handlers can call one helper to obtain “my queued pipeline run tickets” with correct aggregate position/line length and required runner IDs for cancellation.

** DONE [#A] Extend `/api/pipeline/list-workflows` to include queued tickets per pipeline
- Why :: Pipeline pages and dashboard cards should show queued-but-not-started runs alongside started runs, otherwise users lose visibility after start-unification.
- Change ::
  - In `pkg/internal/apis/handlers/pipeline_handler.go`:
    - In `HandleGetPipelineDetails`:
      - After fetching `pipelineRecords`, call the queued-run helper once for the org.
      - Map queued tickets to pipeline IDs by matching `pipeline_identifier` against:
        - pipeline record ID, and
        - canonified path `<orgNamespace>/<pipeline.canonified_name>`.
      - For each matched pipelineID, prepend/append a synthetic “queued run row” to the response slice:
        - Add an optional `queue` object with `ticket_id`, `position`, `line_len`, and `runner_ids`.
        - Populate `runner_ids` and `runner_records` via existing `runners.ResolveRunnerRecords`.
        - Use a deterministic synthetic execution identifier to keep the existing table keying stable:
          - `execution.workflowId = "queue/" + ticket_id`, `execution.runId = ticket_id`.
        - Set `type.name` to the pipeline workflow name (`pipeline.NewPipelineWorkflow().Name()`).
        - Set `status = "queued"` (lowercase, same vocabulary as `/api/pipeline/queue/{ticket}`), and rely on the optional `queue` object for UI branching (do not pass queued status into Temporal UI components).
        - Set `startTime` to the enqueue time (formatted the same way as existing summaries for that user’s timezone).
    - In `HandleGetPipelineSpecificDetails`:
      - Also include queued tickets for just that pipeline ID (filter after mapping).
  - Keep response backward compatible by only adding optional fields; do not change existing fields for started workflows.
- Tests ::
  - Add/extend unit tests in `pkg/internal/apis/handlers/pipeline_handler_test.go` that:
    - Stub queued-run helper to return one queued ticket for a known pipeline,
    - Assert the response includes an entry with `queue.ticket_id` and the correct `position`/`line_len`,
    - Assert `runner_records` resolves when runners exist (fixture-backed), otherwise returns empty but still includes `runner_ids`.
- Done when :: Pipeline list endpoints show queued tickets per pipeline with queue position/length and enough data for the UI to render + cancel.

** DONE [#A] Extend `/api/compliance/checks` (and `/api/my/checks`) list to include queued pipeline tickets
- Why :: The “Workflows” page (`/my/tests/runs`) currently lists Temporal workflows only; queued tickets must appear there too or users cannot see in-progress pipeline runs before they start.
- Change ::
  - In `pkg/internal/apis/handlers/checks_handlers.go` (`HandleListMyChecks`):
    - Determine whether to include queued runs based on the `status` filter:
      - Include queued tickets when no `status` filter is provided OR when the filter includes “running” (treat queued as “in progress”).
      - Exclude queued tickets for purely terminal filters (completed/failed/canceled/etc.).
    - Fetch queued tickets via the shared queued-run helper and append them to the returned `Executions` list as synthetic summaries:
      - Same `execution.workflowId/runId` synthetic scheme as pipeline list endpoints.
      - Same `queue` object shape and `type.name` set to pipeline workflow name.
      - Set `status = "queued"` for these synthetic rows.
      - `displayName`: reuse the existing pipeline-run display convention (e.g. `memo.test` == `"pipeline-run"`), or set a sensible fallback like `"pipeline-run"` so rows are not blank.
    - Ensure sorting remains deterministic (queued rows should not break the hierarchy builder; queued items should be roots with no children).
- Tests ::
  - Add a unit test in `pkg/internal/apis/handlers/checks_handlers_test.go` that:
    - Stubs queued-run helper to return one queued ticket,
    - Calls the list handler with and without `?status=running`,
    - Asserts queued rows are included only under the intended filter behavior and contain queue position/length.
- Done when :: `/my/tests/runs` shows queued pipeline runs (not yet started) and they are not mislabeled as “Running”.

** DONE [#A] Update webapp lists to render queued rows and cancel from queue
- Why :: Current UI assumes every row is a Temporal workflow execution; queued tickets need a distinct label and a different cancellation endpoint.
- Change ::
  - In `webapp/src/lib/workflows/queries.types.ts`:
    - Extend `WorkflowExecutionSummary` with an optional `queue?: { ticket_id: string; position: number; line_len: number; runner_ids: string[] }`.
    - Allow synthetic queued rows by relaxing the execution shape as needed (e.g. tolerate `runId` being a synthetic token); keep existing fields intact for started workflows.
  - In `webapp/src/lib/workflows/workflow-status.svelte`:
    - Extend props to accept optional queue metadata (e.g. `queue?: WorkflowExecutionSummary['queue']`).
    - If `queue` is present, render a “Queued” badge (and optionally `Queued: X of Y` using `position+1` and `max(line_len, position+1)` like existing queue toast formatting).
    - Otherwise keep using Temporal UI status rendering for Temporal statuses.
  - In `webapp/src/lib/workflows/workflow-actions.svelte`:
    - Extend props to accept optional queue metadata (e.g. `queue?: WorkflowExecutionSummary['queue']`) in addition to the existing Temporal workflow identifiers.
    - When `queue` is present, make Cancel call:
      - `DELETE /api/pipeline/queue/{ticket_id}?runner_ids=<csv>` via `pb.send`,
      - and skip calling `/api/my/checks/.../cancel`.
    - When `queue` is absent, keep existing behavior (Cancel only for `Running`, calling `/api/my/checks/{workflowId}/runs/{runId}/cancel`).
  - In `webapp/src/lib/workflows/workflow-table-row.svelte`, `webapp/src/lib/workflows/workflows-table.svelte`, and `webapp/src/lib/workflows/workflows-table-small.svelte`:
    - Do not link queued rows to `/my/tests/runs/...` (render plain text instead of an anchor).
    - Use a stable key that works for both cases (prefer `workflow.queue.ticket_id ?? workflow.execution.runId`).
    - Ensure any status-derived logic never calls `toWorkflowStatusReadable()` for queued rows (branch first on `workflow.queue`), and that cancel uses the queue cancel endpoint for queued rows.
- Tests ::
  - In `webapp/src/lib/workflows` unit tests (Vitest):
    - Add tests that queued rows render “Queued” (and the optional `X of Y` message),
    - Add tests that clicking Cancel for a queued row calls the queue-cancel endpoint (and does not call the Temporal cancel endpoint).
- Done when :: Queued runs render as queued (not running), show queue position/length, and the existing cancel control removes them from the semaphore queue when they are not started.

* DONE [#C] Show pipeline name for queued rows in `/api/compliance/checks`
- Effort :: S
- Goal :: In `/api/compliance/checks` (and `/api/my/checks`) queued pipeline ticket rows use the pipeline name for `displayName` (matching started runs) instead of the fixed `"pipeline-run"`.
- Notes ::
  - Do not change the response shape; only change `displayName` for synthetic queued rows.
  - Match the “real run” name source: when a queued ticket becomes a Temporal pipeline run, `StartQueuedPipelineActivity` sets `memo.test` to the pipeline YAML `name`; queued rows should use the same value.
  - Fall back safely when a pipeline cannot be resolved (never return an empty `displayName`).

** DONE [#C] Resolve pipeline YAML name when building queued summaries
- Why :: Today queued pipeline rows are ambiguous (“pipeline-run”), while started pipeline runs show the pipeline name (from YAML) via `memo.test`.
- Change ::
  - In `pkg/internal/apis/handlers/checks_handlers.go`:
    - Change `buildQueuedWorkflowSummaries(...)` / `buildQueuedWorkflowSummary(...)` to accept `app core.App` (or a `pipelineNameResolver` func) so queued runs can resolve their pipeline definition.
    - Compute `displayName` for each queued run:
      - Resolve the pipeline record via `canonify.Resolve(app, queued.PipelineIdentifier)` (support both `id` and `namespace/canonified_name`).
      - Prefer `pipeline.ParseWorkflow(record.GetString("yaml")).Name` when present.
      - Fallback to `record.GetString("name")`, then to the trimmed identifier, and finally to `"pipeline-run"`.
    - Cache resolved names per `queued.PipelineIdentifier` to avoid repeated DB reads/YAML parsing within the request.
- Tests ::
  - Update `pkg/internal/apis/handlers/checks_list_queued_runs_test.go`:
    - Seed a `pipelines` record owned by userA’s org whose identifier matches the stubbed queued ticket, with YAML containing `name: My Pipeline`.
    - Assert the queued execution summary returns `displayName == "My Pipeline"`.
  - Add a fallback assertion (optional): if the pipeline cannot be resolved, `displayName` remains non-empty.
- Done when :: Queued rows in `/api/compliance/checks` display the pipeline name consistently with started pipeline runs.

* WIP [#A] Align workflow list summaries (queued display name + simple statuses)
- Effort :: M
- Goal :: Make `/api/pipeline/list-workflows` and `/api/(compliance|my)/checks` return (a) the real pipeline name for queued rows and (b) a frontend-friendly CamelCase `status` string for all rows, so UI can stop parsing Temporal enum names.
- Notes ::
  - This is an intentional breaking response change for the list endpoints: we will stop returning Temporal proto enum names in `status` and return only CamelCase status labels (e.g. `Running`, `Canceled`, `TimedOut`, `ContinuedAsNew`).
  - This also fixes internal backend assumptions (e.g. selecting “running” executions) that currently compare against `statusStringRunning` while receiving raw Temporal status enum strings.

** WIP [#A] Return pipeline YAML `name` as `displayName` for queued rows in `/api/pipeline/list-workflows`
- Why :: Queued pipeline rows currently use the generic `"pipeline-run"` label; users can’t distinguish queued items when multiple pipelines are queued. `/api/compliance/checks` already resolves the pipeline name, so `/api/pipeline/list-workflows` should match.
- Change ::
  - In `pkg/internal/apis/handlers/pipeline_handler.go`, update queued row construction (`buildQueuedPipelineSummaries` / `buildQueuedPipelineSummary`) to compute `displayName` from the queued pipeline identifier:
    - Prefer reusing `resolveQueuedPipelineDisplayName(app, queued.PipelineIdentifier)` (already used by checks listing) and cache results within the request to avoid repeated DB reads/YAML parsing.
    - Set `WorkflowExecutionSummary.DisplayName` for queued rows to the resolved name (never blank).
  - Keep all other queued-row fields unchanged (synthetic `execution.workflowId`, `status="queued"`, `queue` object).
- Tests ::
  - Update `pkg/internal/apis/handlers/pipeline_list_workflows_test.go`:
    - In `TestGetPipelineDetailsIncludesQueuedRuns`, assert the queued summary’s `displayName` equals the pipeline YAML `name` (already seeded as `name: queued-pipeline`).
    - Add a fallback assertion (optional): if YAML name missing, `displayName` is still non-empty.
- Done when :: Queued pipeline rows in `/my/pipelines` workflows listings show the actual pipeline name (same as started runs) instead of `"pipeline-run"`.

** TODO [#A] Normalize workflow summary `status` to CamelCase values and stop returning Temporal enum names
- Why :: Today list endpoints return Temporal proto enum strings like `WORKFLOW_EXECUTION_STATUS_RUNNING`, forcing frontend parsing. We already use lowercase status strings in query params (`running`, `canceled`, …) and in queue status responses; summaries should return the same vocabulary directly.
- Change ::
  - Contract:
    - Change the semantics of `WorkflowExecutionSummary.status` for list endpoints:
      - For Temporal-backed rows, return a CamelCase status label:
        - `Running`, `Completed`, `Failed`, `Canceled`, `Terminated`, `TimedOut`, `ContinuedAsNew`, `Unspecified`.
      - For queued synthetic rows, return `status = "Queued"`.
    - Do not add a second “simple” field; only `status` is returned.
  - Backend implementation:
    - Add a small normalizer helper (new file suggested: `pkg/internal/apis/handlers/workflow_status_normalize.go`):
      - `func normalizeTemporalStatus(raw string) string` that maps:
        - `WORKFLOW_EXECUTION_STATUS_RUNNING` -> `Running`
        - `WORKFLOW_EXECUTION_STATUS_COMPLETED` -> `Completed`
        - `WORKFLOW_EXECUTION_STATUS_FAILED` -> `Failed`
        - `WORKFLOW_EXECUTION_STATUS_CANCELED` -> `Canceled`
        - `WORKFLOW_EXECUTION_STATUS_TERMINATED` -> `Terminated`
        - `WORKFLOW_EXECUTION_STATUS_TIMED_OUT` -> `TimedOut`
        - `WORKFLOW_EXECUTION_STATUS_CONTINUED_AS_NEW` -> `ContinuedAsNew`
        - `WORKFLOW_EXECUTION_STATUS_UNSPECIFIED` -> `Unspecified`
      - If `raw` is already one of the CamelCase values (or `Queued`), return it unchanged.
      - Otherwise return `Unspecified` (keep it consistent across endpoints).
    - In `pkg/internal/apis/handlers/checks_handlers.go` (`buildExecutionHierarchy`):
      - Keep using the raw `exec.Status` string for any internal checks (e.g. failure fetching), but set `summary.Status = normalizeTemporalStatus(exec.Status)` in the response DTO.
    - In `pkg/internal/apis/handlers/pipeline_handler.go`:
      - Ensure summaries coming from `buildExecutionHierarchy` already carry normalized `Status`.
      - Update any logic that compares against lowercase status strings to operate on normalized `Status` (e.g. `selectTopExecutionsByPipeline` should compare against `WorkflowStatusRunning` / `"Running"` rather than `statusStringRunning` / `"running"`).
  - Frontend implementation:
    - In `webapp/src/lib/workflows/*`, remove reliance on `@forkbombeu/temporal-ui` status parsing for API responses:
      - Render statuses directly from `workflow.status` (e.g. `Running`, `Canceled`, …).
      - Keep the queued-row branch as-is (`workflow.queue`).
    - Update fixtures like `webapp/src/lib/workflows/queries.test.json` to use the new CamelCase statuses.
- Tests ::
  - Go unit:
    - Add a focused unit test for `normalizeTemporalStatus` covering each mapping.
  - Go handler/unit:
    - Add/update one list test that asserts `status` is CamelCase for a Temporal-backed execution summary.
  - Webapp unit (Vitest):
    - Update existing workflow table/status tests to expect CamelCase statuses and to not call the Temporal enum parser.
- Done when :: `/api/my/checks`, `/api/compliance/checks`, and `/api/pipeline/list-workflows` return only CamelCase status strings for Temporal-backed rows, and the UI renders them without parsing Temporal enum names.

* TODO [#A] Eliminate false “Failed to poll queue” toast after canceling a queued run
- Effort :: S
- Goal :: Canceling a queued run should deterministically end the queue toast with “Queue canceled” (or equivalent) and never show “Failed to poll queue” when cancellation actually succeeded.
- Notes ::
  - Root cause today: `GET /api/pipeline/queue/{ticket}` returns HTTP 404 when the ticket is missing on *all* runners; the frontend poller treats any non-2xx as a polling failure and shows the error toast.
  - Fix should address both sides: make the API respond with a typed `not_found` status, and make the UI stop/ignore polling during cancellation to avoid races.

** TODO [#A] Make queue status endpoint return 200 with `status="not_found"` instead of HTTP 404
- Why :: Polling should be a “status machine” API, not an exception-driven API. A missing ticket is an expected terminal state (especially after cancel).
- Change ::
  - In `pkg/internal/apis/handlers/pipeline_queue_handler.go` (`HandlePipelineQueueStatus`):
    - When `missingRunnerCount == len(requestContext.runnerIDs)`, return `http.StatusOK` with a `PipelineQueueStatusResponse` where:
      - `ticket_id` is echoed back,
      - `runner_ids` is echoed back (if provided),
      - `status = "not_found"`,
      - `position = 0`, `line_len = 0`,
      - omit `workflow_id` / `run_id` / `workflow_namespace`.
    - Keep error responses (bad request, auth, internal Temporal errors) as errors (non-2xx).
- Tests ::
  - Update `pkg/internal/apis/handlers/pipeline_queue_handler_test.go` scenario “poll returns not found”:
    - Expect HTTP 200 and JSON containing `"status":"not_found"` (instead of HTTP 404).
- Done when :: The frontend poller receives a valid status payload even when the ticket disappears, and no longer errors purely due to 404 semantics.

** TODO [#B] Stop queue polling immediately on cancel and treat `not_found` as success during cancel
- Why :: Even with API changes, there is still a race: the poller may observe the ticket disappearing before the cancel request resolves. UX should treat this as “canceled” rather than an error.
- Change ::
  - In `webapp/src/lib/pipeline/utils.ts`:
    - In the cancel action (`cancelQueuedRun`), stop polling before sending the cancel request (so no in-flight poll can emit an error toast after the user intent is clear).
    - In `handleQueueStatus`, when `status.status === 'not_found'`:
      - If a cancel is in flight (or cancellation was requested), finish the queue with “Queue canceled” instead of “Queue ticket not found”.
    - As a defensive fallback, in `pollQueueStatus`’s catch:
      - If the error is a PocketBase `ClientResponseError` with `status === 404`, treat it as `not_found` rather than “Failed to poll queue” (this keeps UX stable during rollout if the backend change is delayed or partially deployed).
- Tests ::
  - Webapp unit (Vitest):
    - Add a focused test for the queue polling/cancel flow that simulates `GET` returning 404 (or `status=not_found`) during cancel and asserts no “Failed to poll queue” toast is emitted.
- Done when :: Canceling a queued run never produces the “Failed to poll queue” toast; the toast resolves to “Queue canceled” even if the ticket disappears mid-poll.
